# Crawler

Reference - https://blog.csdn.net/hp910315/article/details/83926891

| crawler | function | demo |
| ------- | -------- | ---- |
| [WechatSogou](https://github.com/Chyroc/WechatSogou) | 基于搜狗微信搜索的微信公众号爬虫接口 | ![demo-wechat](https://raw.githubusercontent.com/chyroc/wechatsogou/master/screenshot/get_gzh_info.png) |
| [DouBanSpider](https://github.com/lanbing510/DouBanSpider) | 豆瓣读书的爬虫 http://sobook.lanbing510.info | ![demo-douban](https://github.com/lanbing510/DouBanSpider/raw/master/screenshots/douban.jpg) |
| [zhihu_spider](https://github.com/LiuRoy/zhihu_spider) | 知乎爬虫 | ---- |
| [bilibili-user](https://github.com/airingursb/bilibili-user) | :fish_cake: Bilibili 用户爬虫 http://ursb.me/bilibili-report | ---- |
| [SinaSpider](https://github.com/LiuXingMing/SinaSpider) | 新浪微博爬虫（Scrapy、Redis） | ---- |
| [distribute_crawler](https://github.com/gnemoug/distribute_crawler) | 使用scrapy,redis, mongodb,graphite实现的一个分布式网络爬虫,底层存储mongodb集群,分布式使用redis实现,爬虫状态显示使用graphite实现 | ---- |
| [CnkiSpider](https://github.com/yanzhou/CnkiSpider) | 中国知网爬虫 | ---- |
| [LianJiaSpider](https://github.com/lanbing510/LianJiaSpider) | 链家爬虫 http://lanbing510.info/2016/03/15/Lianjia-Spider.html | ![demo-lianJia](https://github.com/lanbing510/LianJiaSpider/raw/master/screenshots/lianjia.jpg) |
| [scrapy_jingdong](https://github.com/taizilongxu/scrapy_jingdong) | 用scrapy写的京东爬虫 | ![demo-jingdong](https://raw.githubusercontent.com/taizilongxu/scrapy_jingdong/master/img.png) |
| [QQ-Groups-Spider](https://github.com/caspartse/QQ-Groups-Spider) | QQ Groups Spider（QQ 群爬虫） http://kagent.applinzi.com/qqun | ![demo-qqgroup](https://raw.githubusercontent.com/caspartse/QQ-Groups-Spider/master/screenshots/screenshot_02.png) |
| [wooyun_public](https://github.com/hanc00l/wooyun_public) | 乌云公开漏洞、知识库爬虫和搜索 crawl and search for wooyun.org public bug(vulnerability) and drops http://www.wooyun.org | ![demo-wooyun](https://raw.githubusercontent.com/hanc00l/wooyun_public/master/search.png) |
| [spider](https://github.com/simapple/spider) | python爬虫 全球网址URL滚动提取 http://www.simapple.com | ---- |
| [findtrip](https://github.com/fankcoder/findtrip) | 机票爬虫（去哪儿和携程网）。flight tickets multiple webspider.(scrapy + selenium + phantomjs + mongodb) | ---- |
| [163spider](https://github.com/leyle/163spider) | 爬取网易客户端内容的小爬虫 | ---- |
| [QQSpider](https://github.com/LiuXingMing/QQSpider) | QQ空间爬虫（日志、说说、个人信息） | ---- |
| [baidu-music-spider](https://github.com/Shu-Ji/baidu-music-spider) | 百度mp3全站爬虫 | ---- |
| [tbcrawler](https://github.com/pakoo/tbcrawler) | 淘宝天猫 商品 爬虫 http://heregoo.com/top/1/ | ---- |
| [stockholm](https://github.com/benitoro/stockholm) | 一个股票数据（沪深）爬虫和选股策略测试框架 | ---- |
| [BaiduyunSpider](https://github.com/k1995/BaiduyunSpider) | 百度云网盘搜索引擎，包含爬虫 & 网站 http://www.githubs.cn | ---- |
| [Spider](https://github.com/Qutan/Spider) | 社交数据爬虫 | ---- |
| [proxy_pool](https://github.com/jhao104/proxy_pool) | Python爬虫代理IP池(proxy pool) | ---- |
| [music-163](https://github.com/RitterHou/music-163) | 爬取网易云音乐所有歌曲的评论数 | ---- |